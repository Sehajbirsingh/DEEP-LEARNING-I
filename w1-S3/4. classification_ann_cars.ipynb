{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e244f1",
   "metadata": {},
   "source": [
    "# Task: Car Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe2bc50",
   "metadata": {},
   "source": [
    "## Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0240172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b93e47f",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65d1016",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CarPrice.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e468ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2621f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006c7422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebff32a",
   "metadata": {},
   "source": [
    "## Check null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffe9979",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc1b320",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CarName'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555ced74",
   "metadata": {},
   "source": [
    "## Label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55c4344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27dc6fb",
   "metadata": {},
   "source": [
    "### encode the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487fb9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [feature for feature in df.columns if df[feature].dtype == 'object']\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37de3675",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "for feature in cat_features:\n",
    "    df[feature] = encoder.fit_transform(df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aefcb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CarName'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1513eb",
   "metadata": {},
   "source": [
    "## Get the x and y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd12f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:, 1:-1]\n",
    "x = x.drop('CarName', axis = 1)\n",
    "y = pd.DataFrame(df['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02432fd0",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7172f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1299ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled = sc.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f26b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482dfc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = x_train.shape[0]\n",
    "n_featuers = x_train.shape[1]\n",
    "print(f'n_samples: {n_samples}, n_features: {n_featuers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382496d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4bbcfe",
   "metadata": {},
   "source": [
    "# Same regression model as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9393fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128 , activation='relu', input_shape=(n_featuers,))) # Input Layer\n",
    "\n",
    "model.add(Dense(64 , activation='relu'))\n",
    "\n",
    "model.add(Dense(32 , activation='relu'))\n",
    "\n",
    "model.add(Dense(32 , activation='relu'))\n",
    "\n",
    "model.add(Dense(8 , activation='relu'))\n",
    "\n",
    "model.add(Dense(8 , activation='relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam',\n",
    "              loss=root_mean_squared_error,\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError()]) # Compiling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b18e4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, validation_split=0.1,\n",
    "                            batch_size = 64, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dd9596",
   "metadata": {},
   "source": [
    "# Binary classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89abb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"CarPrice.csv\")\n",
    "\n",
    "# Encode all object (categorical) columns with LabelEncoder\n",
    "cat_features = [feature for feature in df.columns if df[feature].dtype == 'object']\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "for feature in cat_features:\n",
    "    df[feature] = encoder.fit_transform(df[feature])\n",
    "\n",
    "# Let's say we are predicting fueltype (0 for gas, 1 for diesel).\n",
    "# Make sure \"fueltype\" is indeed 0/1 if not already:\n",
    "# df['fueltype'] = df['fueltype'].map({'gas': 0, 'diesel': 1}) \n",
    "\n",
    "# Check how many unique CarName values\n",
    "print(\"Unique CarName count:\", df['CarName'].nunique())\n",
    "\n",
    "# Let's pick our features: everything from column 1 to second-last,\n",
    "# then drop 'CarName' if it's not useful as a feature\n",
    "X = df.iloc[:, 1:-1]  # or define your own subset of columns\n",
    "X = X.drop('CarName', axis=1, errors='ignore')  # Only drop if CarName is in X\n",
    "\n",
    "# Now define y as the fueltype for binary classification\n",
    "# df.columns might differ, so adjust accordingly\n",
    "y = df['fueltype']\n",
    "\n",
    "# Scale X\n",
    "sc = StandardScaler()\n",
    "X_scaled = sc.fit_transform(X)\n",
    "\n",
    "# Train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_scaled, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0)\n",
    "n_samples = x_train.shape[0]\n",
    "n_features = x_train.shape[1]\n",
    "print(f'n_samples: {n_samples}, n_features: {n_features}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4e2e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define a binary classification model\n",
    "model_binary = Sequential()\n",
    "model_binary.add(Dense(128, activation='relu',\n",
    "                       input_shape=(n_features,),\n",
    "                       kernel_regularizer='l2'))\n",
    "model_binary.add(Dense(64, activation='relu', kernel_regularizer='l2'))\n",
    "model_binary.add(Dense(32, activation='relu', kernel_regularizer='l2'))\n",
    "model_binary.add(Dense(32, activation='relu', kernel_regularizer='l2'))\n",
    "model_binary.add(Dense(8, activation='relu'))\n",
    "model_binary.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Final layer: 1 neuron + sigmoid for binary classification\n",
    "model_binary.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_binary.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',  # Binary crossentropy for binary classification\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(model_binary.summary())\n",
    "\n",
    "# Train\n",
    "history = model_binary.fit(\n",
    "    x_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=10\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "loss, acc = model_binary.evaluate(x_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0fbcaf",
   "metadata": {},
   "source": [
    "# Multi-class model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b7a7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 1) Load Data\n",
    "df = pd.read_csv(\"CarPrice.csv\")\n",
    "\n",
    "# 2) Choose a multi-class column to predict (e.g. 'carbody')\n",
    "#    Suppose 'carbody' has 5 unique values, which is typical (sedan, wagon, hatchback, etc.)\n",
    "#    Convert it into an integer (0..4), then one-hot encode for categorical crossentropy.\n",
    "df['carbody'] = df['carbody'].astype('category')\n",
    "df['carbody_code'] = df['carbody'].cat.codes  # e.g. 0..4\n",
    "y = to_categorical(df['carbody_code'])        # shape becomes (num_samples, 5)\n",
    "\n",
    "# 3) Choose Features (drop or keep columns as needed)\n",
    "#    For simplicity, let's assume we drop 'car_ID' or other ID-like columns:\n",
    "features = [\n",
    "\n",
    "    'fueltype', 'aspiration', 'wheelbase', 'enginesize', 'horsepower',\n",
    "    'citympg', 'highwaympg'\n",
    "   \n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "\n",
    "# Optional: encode or scale as needed.\n",
    "# If 'fueltype' or 'aspiration' are still strings, do LabelEncoder or get_dummies:\n",
    "for col in ['fueltype', 'aspiration']:\n",
    "    if X[col].dtype == object:\n",
    "        X[col] = LabelEncoder().fit_transform(X[col])\n",
    "\n",
    "# 4) Train/Test Split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# 5) Define n_features for the model's input shape\n",
    "n_features = x_train.shape[1]\n",
    "print(\"n_features:\", n_features)\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Model Creation\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model_multiclass = Sequential()\n",
    "model_multiclass.add(Dense(128, activation='relu', \n",
    "                           input_shape=(n_features,), \n",
    "                           kernel_regularizer='l2'))\n",
    "model_multiclass.add(Dense(64, activation='relu', kernel_regularizer='l2'))\n",
    "model_multiclass.add(Dense(32, activation='relu', kernel_regularizer='l2'))\n",
    "model_multiclass.add(Dense(32, activation='relu', kernel_regularizer='l2'))\n",
    "model_multiclass.add(Dense(8, activation='relu'))\n",
    "model_multiclass.add(Dense(8, activation='relu'))\n",
    "# Final layer: 5 neurons + softmax for multi-class\n",
    "model_multiclass.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model_multiclass.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',  # Categorical crossentropy\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model_multiclass.fit(\n",
    "    x_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=10\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "loss, acc = model_multiclass.evaluate(x_test, y_test)  # Use model_multiclass, not model_binary\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a2270b",
   "metadata": {},
   "source": [
    "# Multi-label output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe51913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# 1) Load the dataset\n",
    "df = pd.read_csv(\"CarPrice.csv\")\n",
    "\n",
    "# Example multi-label setup:\n",
    "# Let's say we want to predict three binary columns:\n",
    "#  - fueltype: gas (0) vs. diesel (1)\n",
    "#  - aspiration: std (0) vs. turbo (1)\n",
    "#  - doornumber: two (0) vs. four (1)\n",
    "\n",
    "# Convert each to binary (0/1). If they’re already numeric, skip or adjust as needed:\n",
    "df['fueltype_bin'] = df['fueltype'].map({'gas': 0, 'diesel': 1})\n",
    "df['aspiration_bin'] = df['aspiration'].map({'std': 0, 'turbo': 1})\n",
    "df['doornumber_bin'] = df['doornumber'].map({'two': 0, 'four': 1})\n",
    "\n",
    "# 2) Select the multi-label target (each label is a column in y)\n",
    "y = df[['fueltype_bin', 'aspiration_bin', 'doornumber_bin']].values\n",
    "print(\"y shape:\", y.shape)  # (num_samples, 3)\n",
    "\n",
    "# 3) Choose the feature columns for X\n",
    "#    For example, let’s keep some numeric/categorical columns you want to use.\n",
    "#    Make sure to encode any categorical columns in X.\n",
    "features = [\n",
    "    # Example numeric or already encoded columns\n",
    "    'wheelbase', 'enginesize', 'horsepower', 'citympg', 'highwaympg',\n",
    "    # Possibly keep 'carbody' or 'drivewheel' if you encode them first.\n",
    "]\n",
    "X = df[features]\n",
    "\n",
    "# (Optional) Encode or scale X if needed:\n",
    "# If any columns here are strings, do label-encoding or get_dummies:\n",
    "# for col in ['carbody', 'drivewheel', ...]:\n",
    "#     X[col] = LabelEncoder().fit_transform(X[col])\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 4) Train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "n_features = x_train.shape[1]\n",
    "print(\"n_features:\", n_features)\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Model Creation \n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model_multilabel = Sequential()\n",
    "model_multilabel.add(Dense(128, activation='relu', \n",
    "                           input_shape=(n_features,), \n",
    "                           kernel_regularizer='l2'))\n",
    "model_multilabel.add(Dense(64, activation='relu', kernel_regularizer='l2'))\n",
    "model_multilabel.add(Dense(32, activation='relu', kernel_regularizer='l2'))\n",
    "model_multilabel.add(Dense(32, activation='relu', kernel_regularizer='l2'))\n",
    "model_multilabel.add(Dense(8, activation='relu'))\n",
    "model_multilabel.add(Dense(8, activation='relu'))\n",
    "# Final layer: 3 neurons, each with a sigmoid for multi-label\n",
    "model_multilabel.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model_multilabel.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',  # Each label is binary\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model_multilabel.fit(\n",
    "    x_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=10\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "loss, acc = model_multilabel.evaluate(x_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
