{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lk6X_nyP0agD",
        "outputId": "a716d7c6-5fba-4fbc-cd7a-76fccd19dc16"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, SimpleRNN, GRU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv('./DailyDelhiClimateTest.csv')\n",
        "test_data = pd.read_csv('./DailyDelhiClimateTrain.csv')\n",
        "\n",
        "# Convert date to datetime\n",
        "train_data['date'] = pd.to_datetime(train_data['date'])\n",
        "test_data['date'] = pd.to_datetime(test_data['date'])\n",
        "\n",
        "# Sort data by date\n",
        "train_data = train_data.sort_values('date')\n",
        "test_data = test_data.sort_values('date')\n",
        "\n",
        "# Select features for the model\n",
        "features = ['meantemp', 'humidity', 'wind_speed', 'meanpressure']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train_data[features])\n",
        "test_scaled = scaler.transform(test_data[features])\n",
        "\n",
        "# Function to create sequences\n",
        "def create_sequences(data, seq_length):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X.append(data[i:(i + seq_length), :])\n",
        "        y.append(data[i + seq_length, 0])  # Predicting mean temperature\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Create sequences\n",
        "seq_length = 7  # Use past 7 days to predict the next day\n",
        "X_train, y_train = create_sequences(train_scaled, seq_length)\n",
        "X_test, y_test = create_sequences(test_scaled, seq_length)\n",
        "\n",
        "# Build the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(50, activation='relu', input_shape=(seq_length, len(features))),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Build SimpleRNN model\n",
        "def build_rnn_model():\n",
        "    model = Sequential([\n",
        "        SimpleRNN(50, activation='relu',\n",
        "                  input_shape=(seq_length, len(features)),\n",
        "                  return_sequences=False,  # Output only the last step\n",
        "                  dropout=0.2,             # Dropout for input connections\n",
        "                  recurrent_dropout=0.2),  # Dropout for recurrent connections\n",
        "        Dense(1)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Build LSTM model\n",
        "def build_lstm_model():\n",
        "    model = Sequential([\n",
        "        LSTM(50, activation='tanh',        # Commonly 'tanh' is used in LSTMs\n",
        "             input_shape=(seq_length, len(features)),\n",
        "             return_sequences=False,       # Can be True if stacking LSTM layers\n",
        "             dropout=0.2,                  # Dropout for input connections\n",
        "             recurrent_dropout=0.2),       # Dropout for recurrent connections (memory)\n",
        "        Dense(1)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Build GRU model\n",
        "def create_gru_model():\n",
        "    model = Sequential([\n",
        "        GRU(50, activation='relu',\n",
        "            input_shape=(seq_length, len(features)),\n",
        "            return_sequences=False,       # Set True if using multiple GRU layers\n",
        "            dropout=0.2,                  # Dropout for input connections\n",
        "            recurrent_dropout=0.2),       # Dropout for recurrent connections\n",
        "        Dense(1)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model = build_lstm_model()\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "train_loss = model.evaluate(X_train, y_train, verbose=0)\n",
        "test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Train MSE: {train_loss:.4f}')\n",
        "print(f'Test MSE: {test_loss:.4f}')\n",
        "\n",
        "# Make predictions\n",
        "train_pred = model.predict(X_train)\n",
        "test_pred = model.predict(X_test)\n",
        "\n",
        "def inverse_transform_predictions(scaler, predictions, actual_values):\n",
        "    \"\"\"\n",
        "    Inverse transform scaled predictions and actual values.\n",
        "\n",
        "    Args:\n",
        "    scaler (MinMaxScaler): The fitted scaler used for normalization\n",
        "    predictions (np.array): Scaled predictions\n",
        "    actual_values (np.array): Scaled actual values\n",
        "\n",
        "    Returns:\n",
        "    tuple: Inverse transformed predictions and actual values\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Ensure the scaler has been fitted\n",
        "        if not hasattr(scaler, 'n_features_in_'):\n",
        "            raise ValueError(\"Scaler has not been fitted. Please fit the scaler before using it.\")\n",
        "\n",
        "        # Get the number of features the scaler expects\n",
        "        num_features = scaler.n_features_in_\n",
        "\n",
        "        # Reshape inputs to 2D if they're 1D\n",
        "        predictions = predictions.reshape(-1, 1) if predictions.ndim == 1 else predictions\n",
        "        actual_values = actual_values.reshape(-1, 1) if actual_values.ndim == 1 else actual_values\n",
        "\n",
        "        # Create arrays with zeros for other features\n",
        "        pred_with_zeros = np.column_stack((predictions, np.zeros((len(predictions), num_features - 1))))\n",
        "        actual_with_zeros = np.column_stack((actual_values, np.zeros((len(actual_values), num_features - 1))))\n",
        "\n",
        "        # Perform inverse transform\n",
        "        inv_predictions = scaler.inverse_transform(pred_with_zeros)[:, 0]\n",
        "        inv_actual_values = scaler.inverse_transform(actual_with_zeros)[:, 0]\n",
        "\n",
        "        return inv_predictions, inv_actual_values\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in inverse transformation: {str(e)}\")\n",
        "        return None, None\n",
        "\n",
        "# Usage:\n",
        "try:\n",
        "    train_pred, y_train_actual = inverse_transform_predictions(scaler, train_pred, y_train)\n",
        "    test_pred, y_test_actual = inverse_transform_predictions(scaler, test_pred, y_test)\n",
        "\n",
        "    if train_pred is None or test_pred is None:\n",
        "        raise ValueError(\"Inverse transformation failed\")\n",
        "\n",
        "    print(\"Inverse transformation successful\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {str(e)}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(train_data['date'][seq_length:], y_train_actual, label='Actual (Train)')\n",
        "plt.plot(train_data['date'][seq_length:], train_pred, label='Predicted (Train)')\n",
        "plt.plot(test_data['date'][seq_length:], y_test_actual, label='Actual (Test)')\n",
        "plt.plot(test_data['date'][seq_length:], test_pred, label='Predicted (Test)')\n",
        "plt.title('Mean Temperature Prediction')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Temperature')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtq00-UF9znG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
